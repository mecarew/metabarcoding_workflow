---
title: "Final_taxonomic_checks"
author: "Melissa Carew"
date: "06/06/2024"
output: html_document
---

```{r}
# Load the required libraries
library(dplyr)
library(tidyr)
library(stringr)
library(readxl)

```


```{r}
# read in flies
file_path <- "~/Documents/asv_library_97_jun24.xlsx"

# Get the names of the sheets
sheet_names <- excel_sheets(file_path)

# Read the sheets into separate dataframes
truncated_fills_df <- read_excel(file_path, sheet = sheet_names[1])
otu_groups_df <- read_excel(file_path, sheet = sheet_names[2])
max_p_update_df <- read_excel(file_path, sheet = sheet_names[3])
complexes_df <- read_excel(file_path, sheet = sheet_names[4])

#read in raw dataframe
final_df <- read.csv(here("results/miseq13_raw_data_summary4_Apr_24_unfiltered.csv"))
```

# remove identifications below thresholds for species species, genus, family and order
```{r}
# Update 'species' column to only include names if max threshold is above 97
final_df <-  final_df %>%
  mutate(species = if_else(max_p_identity < 97, "", species))

# Update 'genus' column to only include names if max threshold is above 95
final_df <-  final_df %>%
  mutate(genus = if_else(max_p_identity < 95, "", genus))

# Update 'family' column to only include names if max threshold is above 90
final_df <-  final_df %>%
  mutate(family = if_else(max_p_identity < 90, "", family))

# Update 'order' column to only include names if max threshold is above 80
final_df <-  final_df %>%
  mutate(order = if_else(max_p_identity < 85, "",order))

```


# Fill in truncated samples names
```{r}
# Find common IDs
common_ids <- intersect(truncated_fills_df$asv_code, final_df$asv_code)

print(common_ids)

# Subset data based on common IDs
#subset_final_df <- final_df[final_df$asv_code %in% common_ids, ]
#subset_final_df2 <- grep(is.na(subset_final_df$species))
#subset_asv_table <- truncated_fills_df[truncated_fills_df$asv_code %in% common_ids, ]


df1 <- final_df[final_df$asv_code %in% common_ids, ] # asvs in common in finaldf
df2 <- truncated_fills_df[truncated_fills_df$asv_code %in% common_ids, ]  # asvs in common in truncated_fills_df
df3 <-final_df[!final_df$asv_code %in% common_ids, ] # left data in final dataframe


# Update the 'species' value in df1 based on matching 'asv_code'
for (i in 1:nrow(df1)) {
  target_asv_code <- df1$asv_code[i]
  df1$species[i] <- df2$species[df2$asv_code == target_asv_code]
}

for (i in 1:nrow(df1)) {
  target_asv_code <- df1$asv_code[i]
  df1$genus[i] <- df2$genus[df2$asv_code == target_asv_code]
}

for (i in 1:nrow(df1)) {
  target_asv_code <- df1$asv_code[i]
  df1$family[i] <- df2$family[df2$asv_code == target_asv_code]
}

for (i in 1:nrow(df1)) {
  target_asv_code <- df1$asv_code[i]
  df1$order[i] <- df2$order[df2$asv_code == target_asv_code]
}

for (i in 1:nrow(df1)) {
  target_asv_code <- df1$asv_code[i]
  df1$class[i] <- df2$class[df2$asv_code == target_asv_code]
}

for (i in 1:nrow(df1)) {
  target_asv_code <- df1$asv_code[i]
  df1$phylum[i] <- df2$phylum[df2$asv_code == target_asv_code]
}
 
for (i in 1:nrow(df1)) {
  target_asv_code <- df1$asv_code[i]
  df1$kingdom[i] <- df2$kingdom[df2$asv_code == target_asv_code]
}
print(df1)
```

# Add OTU groupings from Geneiuos denovo analysis
```{r}
# Find common IDs
common_ids2 <- intersect(otu_groups_df$asv_code, df3$asv_code)

# Subset data based on common IDs
#subset_df3 <- df3[df3$asv_code %in% common_ids, ]
#subset_final_df2 <- grep(is.na(subset_final_df$species))
#subset_asv_table <- otu_groups_df[otu_groups_df$asv_code %in% common_ids, ]

df4 <- df3[df3$asv_code %in% common_ids2, ]
df5 <- otu_groups_df[otu_groups_df$asv_code %in% common_ids2, ]
df6 <-df3[!df3$asv_code %in% common_ids2, ]


#df1 <- final_df
print(df1)

# Assuming df1 and df2 are your data frames
# Update the 'species' value in df1 based on matching 'asv_code'
for (i in 1:nrow(df4)) {
  target_asv_code <- df4$asv_code[i]
  df4$species[i] <- df5$species[df5$asv_code == target_asv_code]
}

for (i in 1:nrow(df4)) {
  target_asv_code <- df4$asv_code[i]
  df4$genus[i] <- df5$genus[df5$asv_code == target_asv_code]
}

for (i in 1:nrow(df4)) {
  target_asv_code <- df4$asv_code[i]
  df4$family[i] <- df5$family[df5$asv_code == target_asv_code]
}

for (i in 1:nrow(df4)) {
  target_asv_code <- df4$asv_code[i]
  df4$order[i] <- df5$order[df5$asv_code == target_asv_code]
}

for (i in 1:nrow(df4)) {
  target_asv_code <- df4$asv_code[i]
  df4$class[i] <- df5$class[df5$asv_code == target_asv_code]
}

for (i in 1:nrow(df4)) {
  target_asv_code <- df4$asv_code[i]
  df4$phylum[i] <- df5$phylum[df5$asv_code == target_asv_code]
}
 
for (i in 1:nrow(df4)) {
  target_asv_code <- df4$asv_code[i]
  df4$kingdom[i] <- df5$kingdom[df5$asv_code == target_asv_code]
}

print(df4)

```
# Add in identification data for taxa missing from reference database
```{r}
# Find common IDs
common_ids3 <- intersect(max_p_update_df$asv_code, final_df$asv_code)

# Subset data based on common IDs
#subset_df3 <- df6[df6$asv_code %in% common_ids3, ]
#subset_df62 <- grep(is.na(subset_df6$species))
#subset_asv_table <- max_p_update_df[max_p_update_df$asv_code %in% common_ids, ]

df7 <- df6[df6$asv_code %in% common_ids3, ]
df8 <- max_p_update_df[max_p_update_df$asv_code %in% common_ids3, ]
df9 <-df6[!df6$asv_code %in% common_ids3, ]

# Assuming df1 and df2 are your data frames
# Update the 'species' value in df1 based on matching 'asv_code'
for (i in 1:nrow(df7)) {
  target_asv_code <- df7$asv_code[i]
  df7$species[i] <- df8$species[df8$asv_code == target_asv_code]
}

for (i in 1:nrow(df7)) {
  target_asv_code <- df7$asv_code[i]
  df7$genus[i] <- df8$genus[df8$asv_code == target_asv_code]
}

for (i in 1:nrow(df7)) {
  target_asv_code <- df7$asv_code[i]
  df7$family[i] <- df8$family[df8$asv_code == target_asv_code]
}

for (i in 1:nrow(df7)) {
  target_asv_code <- df7$asv_code[i]
  df7$order[i] <- df8$order[df8$asv_code == target_asv_code]
}

for (i in 1:nrow(df7)) {
  target_asv_code <- df7$asv_code[i]
  df7$class[i] <- df8$class[df8$asv_code == target_asv_code]
}

for (i in 1:nrow(df7)) {
  target_asv_code <- df7$asv_code[i]
  df7$phylum[i] <- df8$phylum[df8$asv_code == target_asv_code]
}
 
for (i in 1:nrow(df7)) {
  target_asv_code <- df7$asv_code[i]
  df7$kingdom[i] <- df8$kingdom[df8$asv_code == target_asv_code]
}

for (i in 1:nrow(df7)) {
  target_asv_code <- df7$asv_code[i]
  df7$max_p_identity[i] <- df8$max_p_identity[df8$asv_code == target_asv_code]
}

print(df7)

```

```{r}
final_data_filled <- rbind(df1, df4, df7, df9)

# Find duplicates in the asv_code column
duplicates <- final_data_filled %>%
  filter(duplicated(asv_code) | duplicated(asv_code, fromLast = TRUE))

# Print the duplicate rows
print(duplicates)
```

```{r}
# saved filled dataframe
write.csv(final_data_filled, "~/git/metabarcoding_workflow/results/miseq13_raw_data_filled_25_jul_24.csv", row.names = FALSE)
```

# Change data to long formmat (list) for PCR replicate filtering 
```{r}
# Pivot longer to transform columns 13 to 40 into rows 
metab_long <- final_data_filled %>%
  pivot_longer(cols = X10BNY29042rep1:Cont3rep1, names_to = "sample", values_to = "value") %>%
  filter(value != 0) %>%  # Filter out rows where value is zero
  select(-matches("^X(\\.\\d+)?$"))  # Remove columns named X, X.1, ..., X.11

# Reorder columns with variable as the first column
metab_long <- metab_long %>%
  select(sample, everything())  # Move variable column to the first position

# Create a new column "replace" by pasting the final character if string ends in 'rep1', 'rep2', or 'rep3'
metab_long <- metab_long %>%
  mutate(replicate = ifelse(grepl("rep[123]$", sample), paste0(substr(sample, nchar(sample), nchar(sample)), ""), ""))

# Move the "replace" column to be the second column
metab_long <- metab_long %>%
  select(sample, replicate, everything())  # Move "replace" to the second column

metab_long <- metab_long %>%
  mutate(sample = str_replace(sample, "^X", ""))

# add 'factor' column
metab_long$site_per <- substr(metab_long$sample, 1, nchar(metab_long$sample))
# remove replicate data
metab_long <- metab_long %>%
   dplyr::mutate(site_per = sub("(rep1|rep2|rep3|rep4|rep5|rep6)$", "", site_per))

# Move the "replace" column to be the second column
metab_long <- metab_long %>%
  select(sample, replicate, site_per, everything())  # Move "replace" to the second column

# add 'factor' column
metab_long$site <- substr(metab_long$site_per, 1, nchar(metab_long$site_per))
# remove replicate data
metab_long <- metab_long %>%
   dplyr::mutate(site = sub("(10|20|30|40|)", "", site))

# Move the "replace" column to be the second column
metab_long <- metab_long %>%
  select(sample, replicate, site_per, site, everything())  # Move "replace" to the second column

# Rename the 'values' column to 'reads' using dplyr's rename()
metab_long <- metab_long %>% rename(`reads` = value)

# Print the transformed data frame
print(metab_long)
```
# Filtering data

# filtering by species subset out data with species ids

```{r}

# Subset where 'species' has non-empty character values
metab_long_with_species <- metab_long %>% filter(!is.na(species) & species != "")

# Subset where 'species' has empty cells or NA (for ASV filtering)
metab_long_empty_species <- metab_long %>% filter(is.na(species) | species == "")
```


# remove single species occurences
```{r}
# Count the occurrences of each combination of 'species' and 'site'
counts <- metab_long_with_species %>%
  group_by(site, species) %>%
  summarise(count = n(), .groups = 'drop')

# Filter out rows where the combination of 'site' and 'species' appears only once
sp_fil_metab_long_with_species <- metab_long_with_species %>%
  left_join(counts, by = c("site", "species")) %>%
  filter(count > 1) %>%
  select(-count)  # Remove the count column as it is no longer needed

# Print the modified dataframe
print(sp_fil_metab_long_with_species)

sp_fil_metab_long_rem <- metab_long_with_species %>% filter((species %in% counts$species[counts$count == 1] & site %in% counts$site[counts$count == 1]))
```
# filter ASVs
Removes ASV's with only a single occurrence in a sample
```{r}
# Count the occurrences of each combination of 'asv_code' and 'site'
counts_asv <- metab_long_empty_species %>% group_by(asv_code, site) %>% summarise(count = n())

# Filter out rows where the count is 1 (i.e., only one occurrence)
asv_fil_metab_long <- metab_long_empty_species %>% filter(!(asv_code %in% counts_asv$asv_code[counts$count == 1] & site %in% counts$site[counts_asv$count == 1]))

#asv_fil_metab_long_rem <- metab_long_empty_species %>% filter((asv_code %in% asv_counts$asv_code[counts$count == 1] & site %in% asv_counts$site[counts$count == 1]))

#print(sp_fil_metab_long_rem)
```

# bind filtered dataframes
```{r}
#rejoin_dataframes
filtered_dataframe <- rbind(sp_fil_metab_long_with_species, asv_fil_metab_long)
```

```{r}
# Step 1: Group by species and summarize the total reads
species_reads <- filtered_dataframe %>%
  group_by(species) %>%
  summarise(total_reads = sum(reads, na.rm = TRUE)) %>%
  arrange(desc(total_reads))

# Print species_reads to verify the summarized data
print(species_reads)

# Step 2: Extract the top 5 species based on 'total_reads' values
top_species <- species_reads %>%
  top_n(5, wt = total_reads) %>%
  pull(species)

# Print top_species to verify the top species
print(top_species)

# Step 3: Filter out reads below 10 for the top 5 species in filtered_dataframe
filtered_dataframe <- filtered_dataframe %>%
  filter(!(species %in% top_species & reads < 10))

# Print the filtered dataframe to verify the result
print(filtered_dataframe)
```

# Full data summary
```{r}
# Assuming final_data_filled is your dataframe
# Step 1: Pivot longer
metab_long <- final_data_filled %>%
  pivot_longer(
    cols = X10BNY29042rep1:Cont3rep1,  # Specify the range or individual column names
    names_to = "sample",
    values_to = "value"
  ) %>%
  filter(value != 0) %>%  # Filter out rows where value is zero
  select(-matches("^X(\\.\\d+)?$"))  # Remove columns named X, X.1, ..., X.11

# Step 2: Pivot wider to transform back to wide format
metab_wide <- metab_long %>%
  pivot_wider(
    names_from = sample,
    values_from = value
  )

# Remove 'X' at the start of column headings
colnames(metab_wide) <- sub("^X", "", colnames(metab_wide))

# List of columns to modify
cols_to_modify <- c('kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species')

# Convert specified columns to character type
metab_wide[cols_to_modify] <- lapply(metab_wide[cols_to_modify], as.character)

# Replace NA values with empty strings in specified columns
metab_wide[cols_to_modify][is.na(metab_wide[cols_to_modify])] <- ""

# Print the first few rows of the resulting dataframe
print(head(metab_wide))


#write_csv(metab_wide, here("results/miseq13_wide.csv"))
```


```{r}
# Summarize values by site name
# Assuming flitered_dataframe is your dataframe
summarized_df <- filtered_dataframe %>%
  group_by(site, kingdom, phylum, class, order, family, genus, species, max_p_identity) %>%  # Group by specified columns including max_p_identity
  summarise(reads = sum(reads, na.rm = TRUE), .groups = 'drop') %>%  # Sum the reads for each group
  group_by(site, kingdom, phylum, class, order, family, genus, species) %>%  # Group by the main columns again
  summarise(
    reads = sum(reads, na.rm = TRUE),  # Sum the reads for each group
    max_p_identity = ifelse(all(is.na(max_p_identity)), NA, max(max_p_identity, na.rm = TRUE)),  # Handle all NA case
    .groups = 'drop'
  )


# Pivot wider to transform the site names into columns
wide_df <- summarized_df %>%
  pivot_wider(names_from = site, values_from = reads, values_fill = 0)  # Fill missing values with 0
```


```{r}
# saved filled dataframe
write.csv(final_data_filled, "~/git/metabarcoding_workflow/results/miseq13_raw_data_filled_filtered_9_jul_24.csv", row.names = FALSE)

```

