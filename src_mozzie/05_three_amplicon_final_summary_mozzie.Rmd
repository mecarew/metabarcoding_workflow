---
title: "Data_summary_from_bioinformatic_pipeline"
author: "Jessica Chung /Melissa Carew"
date: "01/03/2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This notebook arranges the data from the bioinformatic pipeline into a final table for data filling and filtering (in notebaook '06_filling_taxonomy_PCR_rep_filtering'.

```{r}
library(dplyr)
```

# producing data summary table

Starting from here will need the thersholds list and the sample_df from cache03. If it was not saved individually you will need to load the entire cache
```{r}
#load all of cahche03
#load(here::here("results/cache/03.RData"))

# load thresholds_list form cahche03 
thresholds_list <- readRDS(here::here("results/cache/thresholds_list.rds"))
samples_df <- readRDS(here::here("results/cache/samples_df.rds"))
```

# load results files from previuos steps
These tables are required for assembling final data table
```{r}
left_lulu <- readRDS(here::here("results/lulu/left_lulu.rds"))
right_lulu <- readRDS(here::here("results/lulu/right_lulu.rds"))
long_lulu <- readRDS(here::here("results/lulu/long_lulu.rds"))
left_classifications <- qiime2R::read_qza(here::here("results/classification/left_classification.qza"))
right_classifications <- qiime2R::read_qza(here::here("results/classification/right_classification.qza"))
long_classifications <- qiime2R::read_qza(here::here("results/classification/long_classification.qza"))
left_seq <- qiime2R::read_qza(here::here("results/dada2/left_representative_sequences.qza"))
right_seq <- qiime2R::read_qza(here::here("results/dada2/right_representative_sequences.qza"))
long_seq <- qiime2R::read_qza(here::here("results/dada2/long_representative_sequences.qza"))
```

# check classification data for left amplicon
```{r}
left_classifications$data %>% head(100)
```

# check classification data for right amplicon
```{r}
right_classifications$data %>% head(100)
```

# check classification data for long amplicon
```{r}
long_classifications$data %>% head(100)
```


```{r}
# Pull out table of read counts with LULU filter applied
left_lulu$curated_table
```


```{r}
# Pull out table of read counts with LULU filter applied
right_lulu$curated_table
```
```{r}
# Pull out table of read counts with LULU filter applied
long_lulu$curated_table
```

```{r}
# merge left_classifications with thresholds
left_df <- merge(left_classifications$data, thresholds_list[["left"]], by.x="Feature.ID", by.y="feature-id")

right_df <- merge(right_classifications$data, thresholds_list[["right"]], by.x="Feature.ID", by.y="feature-id")

long_df <- merge(long_classifications$data, thresholds_list[["long"]], by.x="Feature.ID", by.y="feature-id")
```

```{r}
left_seq$data %>% head
```

```{r}
right_seq$data %>% head
```

```{r}
long_seq$data %>% head
```

```{r}
left_df %>% arrange(desc(max_p_identity)) %>% head(100)
```

```{r}
right_df %>% arrange(desc(max_p_identity)) %>% head(100)
```
```{r}
long_df %>% arrange(desc(max_p_identity)) %>% head(100)
```

```{r}
table(left_df$Taxon == "Unassigned")
```

```{r}
table(right_df$Taxon == "Unassigned")
```

```{r}
table(long_df$Taxon == "Unassigned")
```

```{r}
left_df %>% filter(Taxon == "Unassigned") %>% pull(max_p_identity) %>% table
```

```{r}
right_df %>% filter(Taxon == "Unassigned") %>% pull(max_p_identity) %>% table
```

```{r}
long_df %>% filter(Taxon == "Unassigned") %>% pull(max_p_identity) %>% table
```

```{r}
# load classification results for left amplicon
left_search_results <- readr::read_tsv(here::here("results/classification/preliminary/left_vsearch.tsv"))
```

```{r}
# # load classification results for right amplicon
right_search_results <- readr::read_tsv(here::here("results/classification/preliminary/right_vsearch.tsv"))
```

```{r}
# # load classification results for right amplicon
long_search_results <- readr::read_tsv(here::here("results/classification/preliminary/long_vsearch.tsv"))
```
## Combine workflow outputs

# fix sample names (if they have 'X' at the start)
This is the case for sampled from the 10 sites study as the names start with numbers

```{r}
all_tables <- list(
  left=left_lulu$curated_table,
  right=right_lulu$curated_table,
  long=long_lulu$curated_table
)
```


```{r}
# Get sample names and groups
sample_groups <- samples_df$factor
names(sample_groups) <- samples_df$sample_name
sample_groups
```

```{r}
##THIS CHUNK ONLY IS NEEDED FOR THE 10 SITE STUDY##
# Need to rename columns to get rid of the prefix X character if sample names start with a digit
#if (all(! colnames(all_tables[[1]]) %in% names(sample_groups))) {
#all_tables <- lapply(all_tables, function(x) {
# colnames(x) <- str_remove(colnames(x), "^X")
#return(x)
#})
#}
```

# combining read tables for the left and right amplicons
```{r}
#make them dataframes
left_read_tab <- all_tables$left
right_read_tab <- all_tables$right
long_read_tab <- all_tables$long
```

```{r}
# Do the amplicon datasets contain the same number of samples?
left_read_tab %>% dim
right_read_tab %>% dim
long_read_tab %>% dim

# are these samples the same for both amplicons?
if(identical(names(left_read_tab), names(right_read_tab))) {
  print("Column names match.")
} else {
  print("Column names do not match.")
}
```

# if column names match skip this step.
```{r}
# # if they do not match which columns are different?
# names_only_in_left_read_tab <- setdiff(names(left_read_tab), names(right_read_tab))
# print("Column names present only in left_read_tab:")
# print(names_only_in_left_read_tab)
# 
# names_only_in_right_read_tab <- setdiff(names(right_read_tab), names(left_read_tab))
# print("Column names present only in right_read_tab:")
# print(names_only_in_right_read_tab)
```

# write scripts to add a blank column to align data for all amplicons
```{r}
# align data set by adding blank column for columns not present in one amplicon but not the other (Cont3rep1, Cont1rep2). 
#left_read_tab <- mutate(left_read_tab, Cont3rep1 = c(0))
#right_read_tab <- mutate(right_read_tab, Cont1rep2 = c(0))
# right_read_tab <- right_read_tab %>%
#   select(-COIPCR1, -COIPCR2, -COIPCR4)
```

```{r}
#merge left and right reads tables into one dataframe
all_read_df <-  rbind(left_read_tab, right_read_tab, long_read_tab)

# covert row headers to column and then name column 1
all_read_df <- tibble::rownames_to_column(all_read_df, var = "asv_code")
```

# combining read classification tables for the left and right amplicons
```{r}
# bind left and right classification data
all_classif_df <-  rbind(left_df, right_df, long_df)

# rename column 1
colnames(all_classif_df)[1] <- "asv_code"

# join into a singe dataframe
all_readclass_df <- left_join(all_classif_df, all_read_df, by = "asv_code")

all_readclass_df <- all_read_df %>%
  left_join(all_classif_df, by = "asv_code")
```

# add in ASV sequence data
```{r}
# put sequences in a dataframe
left_asvseq <- data.frame(left_seq$data)
right_asvseq <- data.frame(right_seq$data)
long_asvseq <- data.frame(long_seq$data)

# covert row headers to column and then name column 1
left_asvseq <- tibble::rownames_to_column(left_asvseq, var = "asv_code")
right_asvseq <- tibble::rownames_to_column(right_asvseq, var = "asv_code")
long_asvseq <- tibble::rownames_to_column(long_asvseq, var = "asv_code")

# add amplicon information
left_asvseq  <- mutate(left_asvseq, amplicon = "left")
right_asvseq <- mutate(right_asvseq, amplicon = "right")
long_asvseq <- mutate(long_asvseq, amplicon = "long")

# align column names for merging
left_asvseq <- left_asvseq %>% dplyr::rename(asv_seq = left_seq.data)
right_asvseq <- right_asvseq %>% dplyr::rename(asv_seq = right_seq.data)
long_asvseq <- long_asvseq %>% dplyr::rename(asv_seq = long_seq.data)

# merge data into a single dataframe
all_asvseq <-  rbind(left_asvseq, right_asvseq, long_asvseq)
```

```{r}
# merge ALL data into a single dataframe
final_df <- all_readclass_df %>%
  left_join(all_asvseq , by = "asv_code")

# remove columns without data
#final_df <- na.omit(final_df)

final_df$Taxon <- gsub("k__", "", final_df$Taxon)
final_df$Taxon <- gsub("p__", "", final_df$Taxon)
final_df$Taxon <- gsub("c__", "", final_df$Taxon)
final_df$Taxon <- gsub("o__", "", final_df$Taxon)
final_df$Taxon <- gsub("f__", "", final_df$Taxon)
final_df$Taxon <- gsub("g__", "", final_df$Taxon)
final_df$Taxon <- gsub("s__", "", final_df$Taxon)

# place taxonomic data in separate columns
final_df <- tidyr::separate(final_df, Taxon, into = c("kingdom", "phylum", "class", "order", "family", "genus","species"), sep = ";",  fill = "right")

# final tidy up (remove 'NA' and X from start of sample names)
final_df[is.na(final_df)] <- ""

head(final_df)

final_df <- final_df %>%
  select(asv_code, kingdom, phylum, class, order, family, genus, species, max_p_identity,	Consensus,	threshold, asv_seq, everything())
```
```{r}
# fix taxonomic discrepancies between BOLD and GenBank
final_df <- final_df %>%
  mutate(
    class = gsub("Copeopda", "Hexanauplia", class),    # Replace 'Copeopda' with 'Hexanauplia'
    order = gsub("Tubificida", "Haplotaxida", order),   # Replace 'Tubificida' with 'Haplotaxida'
     order = gsub("Oomycota", "", order)
   )
# Move 'Oomycota' from 'phylum' to 'class' and replace 'Oomycota' with 'Heterokontophyta' in 'phylum'
final_df<- final_df %>%
  mutate(
    class = ifelse(phylum == "Oomycota", "Oomycota", class),              # Move 'Oomycota' to 'class'
    phylum = ifelse(phylum == "Oomycota", "Heterokontophyta", phylum)     # Replace 'Oomycota' with 'Heterokontophyta'
  )
# Move 'Oomycota' from 'phylum' to 'class' and replace 'Oomycota' with 'Heterokontophyta' in 'phylum'
final_df <- final_df %>%
  mutate(
    class = ifelse(phylum == "Discosea", "Discosea", class),              # Move 'Oomycota' to 'class'
    phylum = ifelse(phylum == "Discosea", "Amoebozoa", phylum)     # Replace 'Oomycota' with 'Heterokontophyta'
  )

final_df <- final_df %>%
  mutate(
    family = gsub("Oceaniidae", "Cordylophoridae", family))   # Replace 'Oceaniidae' with 'Cordylophoridae'
```


```{r}
# save dataframe create a directory for results
dir.create(here::here("results/final_data_summaries"))

timestamp <- format(Sys.time(), "%d_%m_%Y")

# Create the file name with the timestamp 
file_name <- paste0(here::here("results/final_data_summaries/MW_rerun_vsearch_data_summary_"), timestamp, ".csv")

# Save the dataframe with the new file name
write.csv(final_df, file = file_name, row.names = FALSE)
```


