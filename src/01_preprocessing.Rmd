---
title: "Metabarcoding Preprocessing"
description: |
  A QIIME2-based metabarcoding workflow. Part 1.
author:
  - name: Your Name Here
    url: https://example.com/
    affiliation: Example Organisation
    affiliation_url: https://example.com/
    orcid_id: 0000-0000-0000-0000
  - name: Jessica Chung
    url: https://github.com/jessicachung
    affiliation: Melbourne Bioinformatics, PEARG
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
    toc_depth: 4
    df_print: paged
    code_folding: true
    highlight: haddock
    highlight_downlit: false
    css: "custom.css"
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=TRUE, message=TRUE, error=TRUE, echo=TRUE, results="hold")
knitr::opts_knit$set(root.dir = "..")
options(digits=4)
options(width=120)
```


< #TODO: Write documentation about the workflow >



# User settings

First we set the directory that stores the workflow outputs (might move this to a separate file)

```{r}
# You can use the here::here function to define a path relative to the project directory or
results_dir <- here::here("results")
logs_dir <- file.path(results_dir, "logs")
```

The outputs of this workflow will be stored in:  
**`r results_dir`**.

We also have the option to run the jobs in this workflow using SLURM if you're working on a cluster
that uses it.

```{r class.source='fold-show'}
use_slurm <- FALSE

# Settings for slurm (you can ignore these if `use_slurm` is set to FALSE)
slurm_conffile <- here::here("src/.batchtools.conf.R")
slurm_template <- here::here("src/batchtools.slurm.tmpl")
slurm_resources <- list(partition="main", ntasks=1, ncpus=1, memory=4096)
slurm_n_jobs <- 10
```


# Load

We begin by loading the necessary libraries and files.

```{r message=FALSE, warning=FALSE}
suppressPackageStartupMessages({
  library(systemPipeR)
  library(tidyverse)
  library(here)
  library(patchwork)
  library(rmarkdown)
  library(fs)
})

xaringanExtra::use_panelset()
```

And then we add QIIME2 to the environment path (move this to separate file?).

```{r}
# Append qiime2 path to PATH
current_path_env <- Sys.getenv("PATH")
Sys.setenv(PATH=paste0("/mnt/galaxy/gvl/software/shared_envs/qiime2/bin:",
                       current_path_env))
```

And some functions (might move this elsewhere...)

```{r}
extract_targets <- function(x, name) {
  sapply(targets(x), function(x) x[[name]])
}

write_targets <- function(x, file) {
  write.table(x, file=file, quote=FALSE, sep="\t", row.names=FALSE)
}

mkdir <- function(x, quiet=TRUE) {
  if (dir.exists(x)) {
    if (! quiet) message("Directory ", x, " already exists")
  } else {
    dir.create(x)
    if (! quiet) message("Directory ", x, " created")
  }
}

set_logs_dir <- function(wf, logs_dir) {
  wf@yamlinput$results_path$path <- logs_dir
  return(wf)
}

run_jobs <- function(wf, slurm=use_slurm, resources=slurm_resources, quiet=TRUE) {
  if (all(file_exists(unlist(output(wf))))) {
    if (! quiet) message("Output files already exist.")
    runCommandline(wf)
  } else if (! slurm) {
    if (! quiet) message("Running jobs on a single machine")
    runCommandline(wf)
  } else {
    if (! quiet) message("Running jobs on a cluster using SLURM")
    reg <- clusterRun(wf, conffile=slurm_conffile, template=slurm_template, resourceList=resources,
                      Njobs=slurm_n_jobs)
    check <- batchtools::getStatus(reg=reg)
    print(check)
    while(! ((check$done + check$error == check$defined) & (check$queued == 0) & 
          (check$running == 0)) ) {
      Sys.sleep(5)
      check <- batchtools::getStatus(reg=reg)
    }
    if (! quiet) message("Finished!")
    print(check)
    return(reg)
  }
}
```


### Sample information

A file containing sample information is required. We'll read in `data/metadata/samples.tsv` which contains one line for each sample. The columns in the TSV file are required to be:

- `filename_r1`: the path to the FASTQ file containing forward reads of the sequencing run 
- `filename_r2`: the path to the FASTQ file containing reverse reads of the sequencing run
- `sample_name`: a unique sample name
- `factor`: a factor of interest for your dataset (if you don't have a factor of interest, you can set the values as the same as the sample name)

```{r}
samples_df <- read.table(here("data/metadata/samples.tsv"), header=TRUE, stringsAsFactors=FALSE)
paged_table(samples_df)
```



### Barcodes

We also need a file that contains the barcodes that the metabarcoding project uses. We'll read in `ref/barcodes.tsv` which contains one row for each primer used. The columns of this file are required to be:

- `primer`: the unique primer name
- `barcode`: the barcode sequence
- `barcode_rc`: the reverse complement of the barcode.

```{r}
barcodes_filename <- here("ref/barcodes.tsv")
suppressMessages(
  barcodes_df <- read_tsv(barcodes_filename, col_names=c("primer", "barcode", "barcode_rc"))
)
paged_table(barcodes_df)
```



### Barcode combinations

Lastly, we need the group that each primer combination corresponds to. This data is read in from `ref/metadata.tsv` and contains one row for each primer combination. The columns of this file are required to be:

- `sample-id`: the unique name for the primer combination
- `group`: the metabarcoding group that the combination belongs to
- `forward-primer`: the name of the forward primer
- `forward-sequence`: the sequence corresponding to the forward primer
- `reverse-primer`: the name of the reverse primer
- `reverse-sequence`: the sequence corresponding to the reverse primer

```{r}
metadata_filename <- here("ref/metadata.tsv")
suppressMessages(
  metadata_df <- read_tsv(metadata_filename)
)
paged_table(metadata_df)
```


-----

# Import data

To import data into QIIME, the FASTQ files for each library need to be in separate directories.
First, let's check that all files exist from the `samples.tsv` file provided.

```{r}
# Check if all files exist from samples_df
data.frame(sample_name=samples_df$sample_name,
           r1_exists=file.exists(here(samples_df$filename_r1)),
           r2_exists=file.exists(here(samples_df$filename_r2))) %>%
  paged_table()
```

If all the files exist, we can now create a separate directory for each sample and link back to the original FASTQ files using symbolic links (shortcuts).

```{r}
# Create some directories first
dir_create(results_dir)
dir_create(logs_dir)
dir_create(here("tmp"))

# Create symlinks
import_data_dir <- file.path(results_dir, "import_data")
import_targets <- list()
for (i in seq_len(nrow(samples_df))) {
  x <- as.list(samples_df[i,])
  lib_dir <- file.path(import_data_dir, x$sample_name)
  import_targets[[i]] <- lib_dir
  if (! dir.exists(lib_dir)) {
    dir.create(lib_dir, recursive=TRUE)
  }
  stopifnot(str_detect(x$filename_r1, "R1"))
  stopifnot(str_detect(x$filename_r2, "R2"))
  if (! file.exists(file.path(lib_dir, "forward.fastq.gz"))) {
    file.symlink(from=file.path(here(x$filename_r1)),
               to=file.path(lib_dir, "forward.fastq.gz"))
  }
  if (! file.exists(file.path(lib_dir, "reverse.fastq.gz"))) {
    file.symlink(from=file.path(here(x$filename_r2)),
                 to=file.path(lib_dir, "reverse.fastq.gz"))
  }
}
import_targets <- unlist(import_targets)
```

Let's check if these files have been created using the `dir_tree` function:

```{r}
# If there are already qza files generated, don't list them here
dir_tree(here(import_data_dir), regexp="*qza", invert=TRUE)
```

Now we can import these files into a QIIME artifact file.

```{r}
targets <- data.frame(FileName=import_targets,
                      SampleName=basename(import_targets),
                      Factor=basename(import_targets),
                      output=paste0(import_targets, ".qza"))
import_targets <- here("tmp/import_targets.txt")
write.table(targets, file=import_targets, sep="\t", row.names=FALSE, quote=FALSE)
cwl_path <- here("param/cwl")
```

And run the command to import files into QIIME2 artifact files.

::::: {.panelset}

::: {.panel}

#### Run commands {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
import <- loadWorkflow(targets=import_targets, wf_file="qiime_import.cwl", 
    input_file="qiime_import.yml", dir_path=cwl_path)
import <- renderWF(import, inputvars=c(FileName="_INPUT_PATH_", output="_OUTPUT_PATH_"))
import <- set_logs_dir(import, logs_dir)
run_jobs(import)
```

:::

::: {.panel}

#### Command list {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
# If you want to check the commands run, you can use `cmdlist` to do so
cmdlist(import)
```

:::

::: {.panel}

#### Output directory files {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
# List files in output directory
dir_tree(import_data_dir)
```

:::

::::

-----

# Demux

Demuxing is the step that separates barcode combinations within the sample files into separate files.

```{r}
# Setup targets for demux step
demux_dir <- file.path(results_dir, "demux")
mkdir(demux_dir)
targets <- data.frame(FileName=extract_targets(import, "output"),
                      SampleName=extract_targets(import, "SampleName"),
                      Factor=extract_targets(import, "Factor"),
                      metadata_path=metadata_filename) %>%
  mutate(demux_output=file.path(demux_dir, paste0(SampleName, "_demux.qza")),
         discard_output=file.path(demux_dir, paste0(SampleName, "_discard.qza")),
         log_output=file.path(demux_dir, paste0(SampleName, "_cutadapt.log")))
demux_targets <- here("tmp/demux_targets.txt")
write_targets(targets, file=demux_targets)
```


::::: {.panelset}

::: {.panel}

#### Run output {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
demux <- loadWorkflow(targets=demux_targets, wf_file="qiime_demux.cwl", 
    input_file="qiime_demux.yml", dir_path=cwl_path)
demux <- set_logs_dir(demux, logs_dir)
demux <- renderWF(demux, inputvars=c(FileName="_INPUT_PATH_", metadata_path="_BARCODES_FILE_",
                                     demux_output="_OUTPUT_SEQUENCES_", discard_output="_OUTPUT_UNTRIMMED_",
                                     log_output="_LOG_PATH_"))
run_jobs(demux)
```

:::

::: {.panel}

#### Command list {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
# Print commands that were run
cmdlist(demux)
```

:::

::: {.panel}

#### Output directory files {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
# List files in output directory
dir_tree(demux_dir)
```

:::

::::

-----

# Split amplicon groups

Split QIIME qza files into separate files for each amplicon group.

```{r}
# Setup targets
targets <- data.frame(FileName=extract_targets(demux, "demux_output"),
                      SampleName=extract_targets(demux, "SampleName"),
                      Factor=extract_targets(demux, "Factor"),
                      metadata_path=metadata_filename)

target_list <- list()
for (amplicon_group in unique(metadata_df$group)) {
  target_list[[amplicon_group]] <- targets %>%
    mutate(condition=sprintf("[group] == '%s'", amplicon_group),
           output=file.path(demux_dir, paste0(SampleName, "_demux_", amplicon_group, ".qza")),
           sample_id=SampleName,
           SampleName=paste(SampleName, amplicon_group, sep="_"),
           amplicon_group=amplicon_group)
}

targets <- do.call(rbind, target_list)
split_targets <- here("tmp/split_targets.txt")
write_targets(targets, file=split_targets)
```

::::: {.panelset}

::: {.panel}

#### Run output {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
split <- loadWorkflow(targets=split_targets, wf_file="qiime_split.cwl", 
    input_file="qiime_split.yml", dir_path=cwl_path)
split <- set_logs_dir(split, logs_dir)
split <- renderWF(split, inputvars=c(FileName="_INPUT_PATH_", metadata_path="_METADATA_PATH_",
                                     condition="_CONDITION_", output="_OUTPUT_PATH_"))
run_jobs(split)
```

:::

::: {.panel}

#### Command list {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
# Print commands that were run
cmdlist(split)
```

:::

::: {.panel}

#### Output directory files {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
# List files in output directory
dir_tree(demux_dir)
```

:::

::::


-----

# Trim adapters

Use reverse complement sequences to trim any 3' adapters from reads from short fragments.

```{r}
trimmed_dir <- file.path(results_dir, "trimmed")
mkdir(trimmed_dir)
```

Extract adapter sequences from the metadata info.

```{r}
amplicon_groups <- unique(metadata_df$group)
adapter_seq <- list()
for (p in amplicon_groups) {
  primers_f <- metadata_df %>% filter(group == p) %>% pull(`forward-primer`)
  primers_r <- metadata_df %>% filter(group == p) %>% pull(`reverse-primer`)
  adapter_f <- barcodes_df %>% filter(primer %in% primers_f) %>% pull(barcode_rc)
  adapter_r <- barcodes_df %>% filter(primer %in% primers_r) %>% pull(barcode_rc)
  adapter_seq[[p]][["f"]] <- adapter_f
  adapter_seq[[p]][["r"]] <- adapter_r
}
```

```{r}
# Setup targets
targets <- data.frame(FileName=extract_targets(split, "output"),
                      SampleName=extract_targets(split, "SampleName"),
                      Factor=extract_targets(split, "Factor"),
                      metadata_path=metadata_filename,
                      sample_id=extract_targets(split, "sample_id"),
                      amplicon_group=extract_targets(split, "amplicon_group"))

targets <- targets %>% 
  mutate(adapter_f=sapply(targets$amplicon_group, function(x) paste(adapter_seq[[x]][["f"]], collapse=" ")),
         adapter_r=sapply(targets$amplicon_group, function(x) paste(adapter_seq[[x]][["r"]], collapse=" ")),
         output=file.path(trimmed_dir, paste0(SampleName, ".qza")),
         log_path=file.path(trimmed_dir, paste0(SampleName, "_cutadapt_trim.log")))

trimmed_targets <- here("tmp/trimmed_targets.txt")
write_targets(targets, file=trimmed_targets)
```

::::: {.panelset}

::: {.panel}

#### Run output {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
trim <- loadWorkflow(targets=trimmed_targets, wf_file="qiime_trim.cwl", 
    input_file="qiime_trim.yml", dir_path=cwl_path)
trim <- set_logs_dir(trim, logs_dir)
trim <- renderWF(trim, inputvars=c(FileName="_INPUT_PATH_", adapter_f="_ADAPTER_F_",
                                   adapter_r="_ADAPTER_R_", output="_OUTPUT_PATH_",
                                   log_path="_LOG_PATH_"))
run_jobs(trim)
```

:::

::: {.panel}

#### Command list {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
# Print commands that were run
cmdlist(trim)
```

:::

::: {.panel}

#### Output directory files {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
# List files in output directory
dir_tree(trimmed_dir)
```

:::

::::

-----

# Summary and visualisation

Create visualisation files from the previous job.

```{r}
summary_dir <- file.path(results_dir, "summary")
mkdir(summary_dir)

# Setup targets
targets <- data.frame(FileName=extract_targets(trim, "output"),
                      SampleName=extract_targets(trim, "SampleName"),
                      Factor=extract_targets(trim, "Factor"),
                      metadata_path=metadata_filename,
                      sample_id=extract_targets(trim, "sample_id"),
                      amplicon_group=extract_targets(trim, "amplicon_group"))
targets <- targets %>% 
  mutate(output=file.path(summary_dir, paste0(SampleName, ".qzv")),
         output_dir=summary_dir)
summary_targets <- here("tmp/summary_targets.txt")
write_targets(targets, file=summary_targets)

# Setup workflow
summary <- loadWorkflow(targets=summary_targets, wf_file="qiime_summary.cwl", 
    input_file="qiime_summary.yml", dir_path=cwl_path)
summary <- set_logs_dir(summary, logs_dir)
summary@yamlinput$summary_wrapper$path <- file.path(cwl_path, "qiime_summary_wrapper.sh")
summary <- renderWF(summary, inputvars=c(FileName="_INPUT_PATH_", output="_OUTPUT_PATH_",
                                         output_dir="_OUTPUT_DIR_", SampleName="_SAMPLE_NAME_"))
```


::::: {.panelset}

::: {.panel}

#### Run output {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
run_jobs(summary)
```


:::

::: {.panel}

#### Command list {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
# Print commands that were run
cmdlist(summary)
```

:::

::: {.panel}

#### Output directory files {.panel-name}

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"'}
# List files in output directory
dir_tree(summary_dir)
```

:::

::::



### Per sample FASTQ counts

Count how many reads per sample, amplicon group, and primer combination.

```{r}
# Load per-sample-fastq-counts files
summary_files <- list.files(summary_dir, "*per-sample-fastq-counts.tsv", full.names=TRUE)
suppressMessages(
  summary_list <- lapply(summary_files, read_tsv)
)
names(summary_list) <- str_remove(basename(summary_files), 
                                  "_per-sample-fastq-counts.tsv")

# Combine into a single data frame
summary_df <- lapply(names(summary_list), function(x) {
  summary_list[[x]] %>% mutate(library=x)
}) %>% do.call(rbind, .) %>%
  left_join(metadata_df %>% select(`sample-id`, group), by=c("sample ID"="sample-id")) %>% select(library, group, everything())
```



::::: {.panelset}

::: {.panel}

#### Counts per sample {.panel-name}

```{r}
summary_df %>% 
  group_by(`library`) %>% summarise(n=sum(`forward sequence count`)) %>%
  paged_table
```

:::

::: {.panel}

#### Counts per group {.panel-name}

```{r}
summary_df %>% 
  group_by(group) %>% 
  summarise(n=sum(`forward sequence count`)) %>%
  paged_table
```

:::

::: {.panel}

#### Counts per primer combination {.panel-name}

```{r}
summary_df %>% 
  group_by(`sample ID`, group) %>% summarise(n=sum(`forward sequence count`)) %>%
  paged_table
```

:::

::: {.panel}

#### Counts per sample & group & primer combination {.panel-name}


```{r}
summary_df %>% 
  paged_table
```

:::

::::


### Quality plots

Output boxplots to visualise read quality scores.

```{r}
wrangle_seven_number_summary <- function(df) {
  cols <- df[,1,drop=TRUE]
  dat <- data.frame(t(df[,-1]))
  colnames(dat) <- cols
  dat <- dat %>% rownames_to_column("sequence_base") %>%
    mutate(sequence_base=as.numeric(sequence_base))
  return(dat)
}

sequence_quality_plot <- function(dat, title) {
  y_min <- min(0, dat[["9%"]])
  y_max <- max(40, dat[["91%"]])
  ggplot(dat, aes(x=sequence_base, ymin=`9%`, lower=`25%`, middle=`50%`, 
                               upper=`75%`, ymax=`91%`, group=sequence_base)) +
    geom_boxplot(stat="identity") +
    scale_y_continuous(limits=c(y_min, y_max)) +
    theme_bw() +
    labs(title=title,
         x="Sequence Base",
         y="Quality Score") +
    theme(plot.title = element_text(size=12))
}
```

Load TSV file containing quality scores.

```{r}
# Load per-sample-fastq-counts files
forward_files <- list.files(summary_dir, "*forward-seven-number-summaries.tsv", full.names=TRUE)
reverse_files <- list.files(summary_dir, "*reverse-seven-number-summaries.tsv", full.names=TRUE)
suppressWarnings(suppressMessages(
  forward_list <- lapply(forward_files, read_tsv)
))
suppressWarnings(suppressMessages(
  reverse_list <- lapply(reverse_files, read_tsv)
))
names(forward_list) <- str_remove(basename(forward_files), 
                                  "_forward-seven-number-summaries.tsv")
names(reverse_list) <- str_remove(basename(reverse_files), 
                                  "_reverse-seven-number-summaries.tsv")

forward_dat <- lapply(forward_list, wrangle_seven_number_summary)
reverse_dat <- lapply(reverse_list, wrangle_seven_number_summary)

```

Boxplots are a bit dense, so don't plot every sequence base for the read length.

```{r}
# Use every nth base for a boxplot
n <- 2
forward_dat <- lapply(forward_dat, function(df) {df %>% filter(sequence_base %% n == 0)})
reverse_dat <- lapply(reverse_dat, function(df) {df %>% filter(sequence_base %% n == 0)})
```

Output boxplots:

```{r, attr.output='style="max-height: 400px; overflow: auto !important;"', layout="l-body-outset", fig.height=5, fig.width=16}
# Print all amplicon groups (some left and long groups are noise)
plot_order <- summary_df %>% arrange(group, library) %>% pull(library) %>% unique
plot_order <- plot_order[plot_order %in% names(forward_dat)]
for (sample_name in plot_order) {
  if (! str_detect(sample_name, "short|right")) next
  # print(sample_name)
  g_forward <- sequence_quality_plot(forward_dat[[sample_name]],
                                     title=paste0(sample_name, " - Forward Reads"))
  g_reverse <- sequence_quality_plot(reverse_dat[[sample_name]],
                                     title=paste0(sample_name, " - Reverse Reads"))
  print(g_forward + g_reverse)
}
```


# Save output

Save output so it can be loaded in subsequent notebooks.

```{r}
mkdir(here("cache"))
save.image(here("cache/01.RData"))
```

-----

# Session Info

```{r}
if (nzchar(system.file(package="devtools"))) {
  devtools::session_info()
} else {
  sessionInfo()
}
```


